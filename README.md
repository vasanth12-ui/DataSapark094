# Data Sparks_094 - Testing Plan

## Introduction

This repository contains the Test Plan for the **ACME demo application** to ensure the website functions as expected. The testing process includes both manual and automated tests across various b# Data Sparks - Test Plan & Summary Report

## Overview

**Data Sparks** is an ACME web application tested to verify its functionality, performance, and compatibility. The application, designed to showcase various features from **W3Schools** (including tutorials and courses), is undergoing rigorous manual and automated testing to ensure quality before release. This repository contains the Test Plan and Test Summary Report for the application, detailing the testing approaches, tools, and outcomes.

### Product Name
- **Data Sparks**

### Product Description
The W3Schools website provides a comprehensive platform for learning various web technologies. The application includes key features like product search, add to cart, checkout, and account management, as well as financial overview details.

### Project Description
- **Mission of Project**: The goal of this project is to verify the overall functionality of the **ACME web application** to ensure it meets customer expectations through both automated and manual testing.

- **Project Output**: This includes:
  - Test Summary Report
  - Test Plan
  - Test Cases
  - Overall Presentation of Test Results

### Author: 
- **Vasanthakumar G**

---

## Test Summary Report

### Testing Details
- **Total Test Cases**: 42
  - **Functionality Testing**: 35
  - **Performance Testing**: 4
  - **Accessibility Testing**: 3

- **Test Results**:
  - **Passed**: 19
  - **Failed**: 23

### Project Duration
- **Start Date**: 12-Nov-2024
- **End Date**: 16-Nov-2024

---

## Test Plan

### Introduction

The **Data Sparks** test plan outlines the methodologies for functional, performance, and compatibility testing. The plan includes details on the roles and responsibilities of the team, the tools used for testing, the test schedule, entry and exit criteria, and the test deliverables.

### Objectives
- Ensure the functionalities of key features like product search, add to cart, checkout, and account management.
- Confirm compatibility with different browsers (Chrome and Microsoft Edge).

### Scope
The test plan covers:
- Functional testing
- Compatibility testing across browsers

### Testable Features
- Register
- Login
- Forgot password
- Search
- Tutorials
- Courses
- Exercises
- Buttons
- My Learning
- Logout

### Test Approach
- **Testing Types**:
  - Functional Testing
  - Performance Testing
  - System Testing
- **Testing Methodologies**:
  - Black-box Testing
  - Regression Testing
  - User Acceptance Testing (UAT)
- **Testing Environment**:
  - UAT
- **Operating Systems**:
  - Windows 12 and above
- **Browsers**:
  - Chrome, Microsoft Edge

### Roles and Responsibilities
- **Vasanthakumar G**: Responsible for project schedule, test case creation, execution, defect reporting, and coordination.

### Test Schedule
| Task                     | Time Duration       |
|--------------------------|---------------------|
| Test Plan Creation        | 11 Nov 2024         |
| Test Scenario Creation    | 13 Nov 2024         |
| Test Case Creation        | 11-14 Nov 2024      |
| Test Case Execution       | 15 Nov 2024         |
| Summary Report Submission | 15 Nov 2024         |

### Test Deliverables
| Deliverable              | Description                                              | Responsible Owner | Target Completion Date |
|--------------------------|----------------------------------------------------------|-------------------|------------------------|
| Test Plan                | Outlines testing approach, scope, and strategy            | Masai             | 13 Nov 2024            |
| Test Cases               | Detailed test cases for functional and compatibility testing | Masai          | 14 Nov 2024            |
| Defect Reports           | Detailed descriptions of defects found in various versions | Masai             | 15 Nov 2024            |

---

## Entry and Exit Criteria

### Entry Criteria
- All test hardware platforms must be installed and configured correctly.
- All necessary documentation, design, and requirement information should be available.
- Proper test data and test environment setup should be ready.
  
### Exit Criteria
- All high-priority requirements are covered, and no major bugs remain unresolved.
- All high-risk areas have been tested, and the schedule and budget have been met.

---

## Resource and Environment Needs

### Testing Tools
| Process                  | Tool            |
|--------------------------|-----------------|
| Test Case Creation        | Visual Studio   |
| Test Case Tracking        | Visual Studio   |
| Test Case Execution       | Cypress         |
| Test Case Management      | Cypress         |
| Defect Management         | Microsoft Word  |
| Test Reporting            | Excel           |
| Check List Creation       | Microsoft Excel |
| Project Documentation     | Word            |

---

## Approvals
The following items are subject to approval before proceeding:
- Test Plan
- Test Scenarios
- Test Reports

---

## License

This project is licensed under the MIT License - see the [LICENSE.md](LICENSE.md) file for details.
rowsers to guarantee that all key features perform optimally. This document outlines the testing methodology, schedule, roles, and responsibilities to ensure all requirements are met.

## Objectives

The goal of this testing is to:
- Ensure the core functionalities of the application (such as registration, login, search, etc.) are working as expected.
- Verify compatibility across different browsers (Chrome and Microsoft Edge).
  
## Scope

This Test Plan focuses on:
- Functional testing
- Compatibility testing across multiple browsers.
  
### Testable Features

The following features of the **ACME demo application** will be tested:
- Register
- Login
- Forgot password
- Java functionalities
- Search
- Tutorials
- Courses
- Exercise
- Buttons
- My Learning
- Logout

## Test Approach

### Testing Types
- **Functional Testing**: Ensure all features are working as expected.
- **Performance Testing**: Test the application for speed, scalability, and performance.
- **System Testing**: Check overall functionality of the entire system.

### Testing Methodologies
- **Black-box Testing**: Test functionalities without knowledge of the internal workings.
- **Regression Testing**: Ensure new updates do not break existing features.
- **User Acceptance Testing (UAT)**: Ensure the application meets end-user expectations.

### Testing Environment
- **UAT Environment** for testing
- **Operating Systems**: Windows 12 and above
- **Browsers**: Chrome, Microsoft Edge

## Roles and Responsibilities

### QA Tester
- **Vasanthakumar G**: Primary contact for the project, responsible for:
  - Creating, reviewing, and executing test cases
  - Reporting defects and retesting them
  - Coordinating with the QA Lead for test preparations, execution, and defect management

## Testing Schedule

The planned schedule for the project is as follows:

| Task                | Time Duration   |
|---------------------|-----------------|
| Test Plan creation   | 11 Nov 2024     |
| Test Scenario creation | 13 Nov 2024   |
| Test Case creation   | 11-14 Nov 2024  |
| Test Case Execution  | 15 Nov 2024     |
| Summary Report Submission | 15 Nov 2024 |

## Test Deliverables

The following deliverables will be produced and shared with the client:

| Deliverable         | Description                                           | Responsible Owner | Target Completion Date |
|---------------------|-------------------------------------------------------|-------------------|------------------------|
| Test Plan           | Outlines testing strategy, scope, and methodologies.  | Masai             | 13 Nov 2024            |
| Test Cases          | Detailed test cases for functional and compatibility testing. | Masai         | 14 Nov 2024            |
| Defect Reports      | Detailed descriptions of defects identified.          | Masai             | 15 Nov 2024            |

## Entry and Exit Criteria

### Entry Criteria
- All necessary documentation, tools, and test environments are in place.
- Test data and resources are available.
- QA team has sufficient knowledge of requirements.

### Exit Criteria
- All major requirements have been tested, with only minor residual risks.
- No critical bugs are left unaddressed.
- Project timeline and budget have been met.

## Resource and Environment Needs

### Testing Tools
- **Test Case Creation**: Visual Studio
- **Test Case Tracking**: Visual Studio
- **Test Case Execution**: Cypress
- **Test Case Management**: Cypress
- **Defect Management**: Microsoft Word
- **Test Reporting**: Excel
- **Check List Creation**: Microsoft Excel
- **Project Documentation**: Word

## Approvals

- Test Plan
- Test Scenarios
- Test Reports

## License

This project is licensed under the MIT License - see the [LICENSE.md](LICENSE.md) file for details.
# DataSapark094
Dark_spark094
